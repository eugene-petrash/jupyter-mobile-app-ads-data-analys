{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitable App Profiles for the App Store and Google Play Markets\n",
    "Our aim in this project is to find mobile app profiles that are profitable for the App Store and Google Play markets. We're working as data analysts for a company that builds Android and iOS mobile apps, and our job is to enable our team of developers to make data-driven decisions with respect to the kind of apps they build.\n",
    "\n",
    "At our company, we only build apps that are free to download and install, and our main source of revenue consists of in-app ads. This means that our revenue for any given app is mostly influenced by the number of users that use our app. Our goal for this project is to analyze data to help our developers understand what kinds of apps are likely to attract more users.\n",
    "\n",
    "# Opening and Exploring the Data\n",
    "As of September 2018, there were approximately 2 million iOS apps available on the App Store, and 2.1 million Android apps on Google Play.\n",
    "\n",
    "Collecting data for over four million apps requires a significant amount of time and money, so we'll try to analyze a sample of data instead. To avoid spending resources with collecting new data ourselves, we should first try to see whether we can find any relevant existing data at no cost. Luckily, these are two data sets that seem suitable for our purpose:\n",
    "\n",
    "* [A data set](https://www.kaggle.com/lava18/google-play-store-apps/home) containing data about approximately ten thousand Android apps from Google Play\n",
    "* [A data set](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home) containing data about approximately seven thousand iOS apps from the App Store\n",
    "Let's start by opening the two data sets and then continue with exploring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "with open(\"data_sets/AppleStore.csv\", encoding='utf8') as file_opened:\n",
    "    file_readed = list(reader(file_opened))\n",
    "    apple_data = file_readed[1:]\n",
    "    apple_headers = file_readed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "with open(\"data_sets/googleplaystore.csv\", encoding='utf8')as file_opened:\n",
    "    file_readed = list(reader(file_opened))\n",
    "    google_data = file_readed[1:]\n",
    "    google_headers = file_readed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to explore the two data sets, we'll first write a function named explore_data() that we can use repeatedly to explore rows in a more readable way. We'll also add an option for our function to show the number of rows and columns for any data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(\"%s\\n\" % row)\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to explore the two data sets, we'll first write a function named explore_data() that we can use repeatedly to explore rows in a more readable way. We'll also add an option for our function to show the number of rows and columns for any data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App\n",
      "\n",
      "Category\n",
      "\n",
      "Rating\n",
      "\n",
      "Reviews\n",
      "\n",
      "Size\n",
      "\n",
      "Installs\n",
      "\n",
      "Type\n",
      "\n",
      "Price\n",
      "\n",
      "Content Rating\n",
      "\n",
      "Genres\n",
      "\n",
      "Last Updated\n",
      "\n",
      "Current Ver\n",
      "\n",
      "Android Ver\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(google_headers, 0, len(google_headers), False)\n",
    "explore_data(google_data, 0, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Google Play data set has 10841 apps and 13 columns. At a quick glance, the columns that might be useful for the purpose of our analysis are 'App', 'Category', 'Reviews', 'Installs', 'Type', 'Price', and 'Genres'.\n",
    "\n",
    "Now let's take a look at the App Store data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "id\n",
      "\n",
      "track_name\n",
      "\n",
      "size_bytes\n",
      "\n",
      "currency\n",
      "\n",
      "price\n",
      "\n",
      "rating_count_tot\n",
      "\n",
      "rating_count_ver\n",
      "\n",
      "user_rating\n",
      "\n",
      "user_rating_ver\n",
      "\n",
      "ver\n",
      "\n",
      "cont_rating\n",
      "\n",
      "prime_genre\n",
      "\n",
      "sup_devices.num\n",
      "\n",
      "ipadSc_urls.num\n",
      "\n",
      "lang.num\n",
      "\n",
      "vpp_lic\n",
      "\n",
      "['1', '281656475', 'PAC-MAN Premium', '100788224', 'USD', '3.99', '21292', '26', '4', '4.5', '6.3.5', '4+', 'Games', '38', '5', '10', '1']\n",
      "\n",
      "Number of rows: 7197\n",
      "Number of columns: 17\n"
     ]
    }
   ],
   "source": [
    "explore_data(apple_headers, 0, len(apple_headers), False)\n",
    "explore_data(apple_data, 0, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 7197 iOS apps in this data set, and the columns that seem interesting are: 'track_name', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', and 'prime_genre'. Not all column names are self-explanatory in this case, but details about each column can be found in the data set [documentation](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting Wrong Data\n",
    "The Google Play data set has a dedicated [discussion section](https://www.kaggle.com/lava18/google-play-store-apps/discussion) , and we can see that [one of the discussions](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) outlines an error for row 10472. Let's print this row and compare it against the header and another row that is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "\n",
      "\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n"
     ]
    }
   ],
   "source": [
    "print(google_data[10472])  # incorrect row\n",
    "print('\\n')\n",
    "print(google_headers)  # header\n",
    "print('\\n')\n",
    "print(google_data[0])      # correct row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The row 10472 corresponds to the app Life Made WI-Fi Touchscreen Photo Frame, and we can see that the rating is 19. This is clearly off because the maximum rating for a Google Play app is 5. As a consequence, we'll delete this row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10841\n",
      "10840\n"
     ]
    }
   ],
   "source": [
    "print(len(google_data))\n",
    "del google_data[10472]  # don't run this more than once\n",
    "print(len(google_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Removing Duplicate EntriesÂ¶\n",
    "## Part One\n",
    "Let's analyze datasets to detect duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_duplicates(data_set, data_set_name):\n",
    "    unique_apps = []\n",
    "    duplicate_apps = []\n",
    "    for row in data_set:\n",
    "        app = row[0]\n",
    "        if app in unique_apps:\n",
    "            duplicate_apps.append(app)\n",
    "        else:\n",
    "            unique_apps.append(app)\n",
    "\n",
    "    print(\"%s unique_apps: %s\" % (data_set_name, len(unique_apps)))\n",
    "    print(\"%s duplicate_apps: %s\" % (data_set_name, len(duplicate_apps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check the OS data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS unique_apps: 7197\n",
      "OS duplicate_apps: 0\n"
     ]
    }
   ],
   "source": [
    "analyze_duplicates(apple_data, \"OS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily the OS data set is unique. Let's check Android data as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Android unique_apps: 9659\n",
      "Android duplicate_apps: 1181\n"
     ]
    }
   ],
   "source": [
    "analyze_duplicates(google_data, \"Android\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the Android data set contains 1181 duplicated entries.\n",
    "\n",
    "Examples of duplicate apps: ['Quick PDF Scanner + OCR FREE', 'Box', 'Google My Business', 'ZOOM Cloud Meetings', 'join.me - Simple Meetings', 'Box', 'Zenefits', 'Google Ads', 'Google My Business', 'Slack', 'FreshBooks Classic', 'Insightly CRM', 'QuickBooks Accounting: Invoicing & Expenses', 'HipChat - Chat Built for Teams', 'Xero Accounting Software']\n",
    "\n",
    "We don't want to count certain apps more than once when we analyze data, so we need to remove the duplicate entries and keep only one entry per app. One thing we could do is remove the duplicate rows randomly, but we could probably find a better way.\n",
    "\n",
    "If you examine the rows we printed two cells above for the Instagram app, the main difference happens on the fourth position of each row, which corresponds to the number of reviews. The different numbers show that the data was collected at different times. We can use this to build a criterion for keeping rows. We won't remove rows randomly, but rather we'll keep the rows that have the highest number of reviews because the higher the number of reviews, the more reliable the ratings.\n",
    "\n",
    "To do that, we will:\n",
    "\n",
    "* Create a dictionary where each key is a unique app name, and the value is the highest number of reviews of that app\n",
    "* Use the dictionary to create a new data set, which will have only one entry per app (and we only select the apps with the highest number of reviews)\n",
    "\n",
    "## Part Two\n",
    "Let's start by building the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "\n",
    "for row in google_data:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    if name in reviews_max.keys():\n",
    "        if reviews_max[name] < n_reviews:\n",
    "            reviews_max[name] = n_reviews\n",
    "    else:\n",
    "        reviews_max[name] = n_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous code cell, we found that there are 1,181 cases where an app occurs more than once, so the length of our dictionary (of unique apps) should be equal to the difference between the length of our data set and 1,181."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected length: 9659\n",
      "Actual length: 9659\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Expected length:', len(google_data) - 1181)\n",
    "print('Actual length:', len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the reviews_max dictionary to remove the duplicates. For the duplicate cases, we'll only keep the entries with the highest number of reviews. In the code cell below:\n",
    "\n",
    "* We start by initializing two empty lists, android_clean and already_added.\n",
    "* We loop through the android data set, and for every iteration:\n",
    "    * We isolate the name of the app and the number of reviews.\n",
    "    * We add the current row (app) to the android_clean list, and the app name (name) to the already_cleaned list if:\n",
    "The number of reviews of the current app matches the number of reviews of that app as described in the reviews_max dictionary; and\n",
    "The name of the app is not already in the already_added list. We need to add this supplementary condition to account for those cases where the highest number of reviews of a duplicate app is the same for more than one entry (for example, the Box app has three entries, and the number of reviews is the same). If we just check for reviews_max[name] == n_reviews, we'll still end up with duplicate entries for some apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_set = []\n",
    "already_added = []\n",
    "\n",
    "for row in google_data:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    if n_reviews == reviews_max[name] and name not in already_added:\n",
    "        clean_data_set.append(row)\n",
    "        already_added.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's quickly explore the new data set, and confirm that the number of rows is 9,659."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "['U Launcher Lite â FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "Number of rows: 9659\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(clean_data_set, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 9659 rows, just as expected."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
